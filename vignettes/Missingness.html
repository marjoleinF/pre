<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Marjolein Fokkema" />


<title>Dealing with missing data in fitting prediction rule ensembles</title>

<script src="data:application/javascript;base64,Ly8gUGFuZG9jIDIuOSBhZGRzIGF0dHJpYnV0ZXMgb24gYm90aCBoZWFkZXIgYW5kIGRpdi4gV2UgcmVtb3ZlIHRoZSBmb3JtZXIgKHRvCi8vIGJlIGNvbXBhdGlibGUgd2l0aCB0aGUgYmVoYXZpb3Igb2YgUGFuZG9jIDwgMi44KS4KZG9jdW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignRE9NQ29udGVudExvYWRlZCcsIGZ1bmN0aW9uKGUpIHsKICB2YXIgaHMgPSBkb2N1bWVudC5xdWVyeVNlbGVjdG9yQWxsKCJkaXYuc2VjdGlvbltjbGFzcyo9J2xldmVsJ10gPiA6Zmlyc3QtY2hpbGQiKTsKICB2YXIgaSwgaCwgYTsKICBmb3IgKGkgPSAwOyBpIDwgaHMubGVuZ3RoOyBpKyspIHsKICAgIGggPSBoc1tpXTsKICAgIGlmICghL15oWzEtNl0kL2kudGVzdChoLnRhZ05hbWUpKSBjb250aW51ZTsgIC8vIGl0IHNob3VsZCBiZSBhIGhlYWRlciBoMS1oNgogICAgYSA9IGguYXR0cmlidXRlczsKICAgIHdoaWxlIChhLmxlbmd0aCA+IDApIGgucmVtb3ZlQXR0cmlidXRlKGFbMF0ubmFtZSk7CiAgfQp9KTsK"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="data:text/css,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Dealing with missing data in fitting prediction rule ensembles</h1>
<h4 class="author">Marjolein Fokkema</h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>To deal with missing data, multiple imputation is the golden standard (). With GLMs, the models fitted on each imputed dataset can then be pooled. For non-parameteric methods, such pooling is more difficult. With prediction rule ensembles, there are several ways to deal with missing data:</p>
<ul>
<li><p>Listwise deletion. This is certainly the least favorable option, but already implemented in function <code>pre()</code>.</p></li>
<li><p>Single imputation: Perform only a single imputation and fit a prediction rule ensemble on this single dataset. This is likely better than listwise deletion, but likely inferior to multiple imputation. This can be easily done by the user.</p></li>
<li><p>Multiple imputation approach 1): Perform multiple imputation. Fit a separate prediction rule ensemble on each of the imputed datasets. Aggregate the ensembles into a single final ensemble. In terms of predictive accuracy, this approach will work best. Note that this also results in predicted values being aggregated, instead of model coefficients being aggregated and pred</p></li>
<li><p>Multiple imputation approach 2): Perform multiple imputation. Aggregate the datasets into one large dataset. Fit a single prediction rule on this large dataset. The artificially inflated sample size will have two main consequences when fitting the prediction rule ensemble: First, the trees fitted for rule generation may get deeper. Second, the RSS in the fitting of the penalized regression model will be inflated, yielding a lower amount of penalization than would be optimal given the true sample size. The first consequence is much reduced by retaining low maximum tree depth. The second consequence can be reduced by ‘correcting’ the optimal penalty parameter value for the artificially inflated sample size.</p></li>
<li><p>Combining mean imputation with the Missing-In-Attributes approach. According to Josse et al. (2019), mean imputation and the Missing-In-Attributes approaches are not so bad from a prediction perspective. Furthermore, they are computationally inexpensive. For rule generation, we could employ the MIA approach as implemented in function <code>ctree</code>. For fitting the penalized regression model, we need to obtain a complete model matrix. The rule variables can be obtained as complete data using the MIA approach. Mean imputation can be applied to the original predictor variables.</p></li>
</ul>
<p>Below, we provide examples for the two multiple imputation approaches. In future versions of package <strong><code>pre</code></strong>, the mean imputation combined with MIA approach will be implemented.</p>
</div>
<div id="example-predicting-wind-speed" class="section level2">
<h2>Example: Predicting wind speed</h2>
<p>For the examples, we will be predicting Wind speels using the <code>airquality</code> dataset (we focus on predicting the <code>wind</code> variable, because it does not have missing values, while variables <code>Ozone</code> and <code>Solar.R</code> do):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(airquality)</span></code></pre></div>
<pre><code>##   Ozone Solar.R Wind Temp Month Day
## 1    41     190  7.4   67     5   1
## 2    36     118  8.0   72     5   2
## 3    12     149 12.6   74     5   3
## 4    18     313 11.5   62     5   4
## 5    NA      NA 14.3   56     5   5
## 6    28      NA 14.9   66     5   6</code></pre>
<p>We perform multiple imputation by chained equations, using the predictive mean matching method. We generate 5 imputed datasets:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mice&quot;</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">md.pattern</span>(airquality)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(airquality, <span class="at">m =</span> <span class="dv">5</span>)</span></code></pre></div>
</div>
<div id="multiple-imputation-aggregate-ensembles" class="section level2">
<h2>Multiple imputation: Aggregate ensembles</h2>
<p>We create a <code>list</code> with imputed datasets:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>imp1 <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp, <span class="at">action =</span> <span class="st">&quot;all&quot;</span>, <span class="at">include =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>We load the <strong><code>pre</code></strong> library:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;pre&quot;</span>)</span></code></pre></div>
<p>We create a custom function that fits PREs to several datasets contained in a list:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>pre.agg <span class="ot">&lt;-</span> <span class="cf">function</span>(datasets, ...) {</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(datasets)) {</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    result[[i]] <span class="ot">&lt;-</span> <span class="fu">pre</span>(datasets[[i]], ...)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  result</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We apply the new function:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>airq.agg <span class="ot">&lt;-</span> <span class="fu">pre.agg</span>(imp1, <span class="at">formula =</span> Wind <span class="sc">~</span> .)</span></code></pre></div>
<p>Note that we can used the ellipsis (<code>...</code>) to pass arguments to <code>pre</code> (see <code>?pre</code> for an overview of arguments that can be specified).</p>
<p>We now define <code>print</code>, <code>summary</code>, <code>predict</code> and <code>coef</code> methods to extract results from the fitted ensemble. Again, we can use the ellipsis (<code>...</code>) to pass arguments to the <code>print</code>, <code>summary</code>, <code>predict</code> and <code>coef</code> methods of function <code>pre</code> (see e.g., <code>?pre:::print.pre</code> for more info):</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>print.agg <span class="ot">&lt;-</span> <span class="cf">function</span>(object, ...) {</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  result <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sink</span>(<span class="st">&quot;NULL&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(object)) {</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    result[[i]] <span class="ot">&lt;-</span> <span class="fu">print</span>(object[[i]], ...)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sink</span>()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(result)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print.agg</span>(airq.agg) <span class="do">## results suppressed for space considerations</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>summary.agg <span class="ot">&lt;-</span> <span class="cf">function</span>(object, ...) {</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(object)) <span class="fu">summary</span>(object[[i]], ...)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="fu">summary.agg</span>(airq.agg) <span class="do">## results suppressed for space considerations</span></span></code></pre></div>
<p>For averaging over predictions, there is only one option for continuous outcomes. For non-continuous outcomes, we can average over the linear predictor, or over the predicted values on the scale of the response. I do not know which would be more appropriate. The resulting predicted values will be highly correlated, though.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>predict.agg <span class="ot">&lt;-</span> <span class="cf">function</span>(object, newdata, ...) {</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowMeans</span>(<span class="fu">sapply</span>(object, predict, <span class="at">newdata =</span> newdata, ...))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>agg_preds <span class="ot">&lt;-</span> <span class="fu">predict.agg</span>(airq.agg, <span class="at">newdata =</span> airquality[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, ])</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>agg_preds</span></code></pre></div>
<pre><code>##        1        2        3        4 
## 10.42757 10.59272 10.93324 11.00302</code></pre>
<p>Finally, the <code>coef</code> method should return the averaged / aggregated final PRE. That is, it returns:</p>
<ol style="list-style-type: decimal">
<li><p>One averaged intercept;</p></li>
<li><p>All rules and linear terms, with their coefficients scaled by the number of datasets;</p></li>
<li><p>In presence of identical rules and linear terms, it aggregates those rules and their coefficients into one rule / term, and adds together the scaled coefficients.</p></li>
</ol>
<p>Note that linear terms that do not have the same winsorizing points will not be aggregated. Note that the labels of rules and variables may overlap between different datasets (e.g., the label <code>rule 12</code> or may appear multiple times in the aggregated ensemble, but each <code>rule 12</code> will have different conditions).</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>coef.agg <span class="ot">&lt;-</span> <span class="cf">function</span>(object, ...) {</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(object[[<span class="dv">1</span>]], ...)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  coefs <span class="ot">&lt;-</span> coefs[coefs<span class="sc">$</span>coefficient <span class="sc">!=</span> <span class="dv">0</span>,]</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(object)) {</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    coefs_tmp <span class="ot">&lt;-</span> <span class="fu">coef</span>(object[[i]], ...)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    coefs_tmp <span class="ot">&lt;-</span> coefs_tmp[coefs_tmp<span class="sc">$</span>coefficient <span class="sc">!=</span> <span class="dv">0</span>,]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Add intercepts:</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    coefs[coefs<span class="sc">$</span>rule <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>, <span class="st">&quot;coefficient&quot;</span>] <span class="ot">&lt;-</span> </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>      coefs[coefs<span class="sc">$</span>rule <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>, <span class="st">&quot;coefficient&quot;</span>] <span class="sc">+</span> </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>      coefs_tmp[coefs_tmp<span class="sc">$</span>rule <span class="sc">==</span> <span class="st">&quot;(Intercept)&quot;</span>, <span class="st">&quot;coefficient&quot;</span>]</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Append other terms rest to coefs:</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    coefs <span class="ot">&lt;-</span> <span class="fu">rbind</span>(coefs, coefs_tmp[coefs_tmp<span class="sc">$</span>rule<span class="sc">!=</span> <span class="st">&quot;(Intercept)&quot;</span>, ])</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Divide coefficients by the number of datasets:</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  coefs<span class="sc">$</span>coefficient <span class="ot">&lt;-</span> coefs<span class="sc">$</span>coefficient <span class="sc">/</span> <span class="fu">length</span>(object)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Identify identical rules:</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  duplicates <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">duplicated</span>(coefs<span class="sc">$</span>description))</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> duplicates) {</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    first_match <span class="ot">&lt;-</span> <span class="fu">which</span>(coefs<span class="sc">$</span>description <span class="sc">==</span> coefs<span class="sc">$</span>description[i])[<span class="dv">1</span>]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Add the coefficients:</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    coefs<span class="sc">$</span>coefficient[first_match] <span class="ot">&lt;-</span> </span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>      coefs<span class="sc">$</span>coefficient[first_match] <span class="sc">+</span> coefs<span class="sc">$</span>coefficient[i]</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Remove duplicates:</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  coefs <span class="ot">&lt;-</span> coefs[<span class="sc">-</span>duplicates, ]</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Return results:</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  coefs</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="fu">coef.agg</span>(airq.agg)</span></code></pre></div>
<pre><code>##            rule   coefficient                 description
## 65  (Intercept)  9.4335719838                           1
## 29       rule32 -0.1428273137      Temp &gt; 73 &amp; Ozone &gt; 23
## 3         rule3  0.9687460335                 Ozone &lt;= 45
## 7         rule7 -0.0941839171 Ozone &gt; 14 &amp; Solar.R &lt;= 238
## 66        Ozone -0.0057739123         7 &lt;= Ozone &lt;= 115.6
## 6         rule6  0.0748353528                 Ozone &lt;= 59
## 25       rule26 -0.0677719739      Temp &gt; 63 &amp; Ozone &gt; 14
## 17       rule17 -0.0380923160      Temp &gt; 75 &amp; Ozone &gt; 47
## 1         rule1  0.0907492725                 Ozone &lt;= 21
## 71        rule7  0.1346917293                 Ozone &lt;= 37
## 291      rule32  0.2401553456                 Ozone &lt;= 47
## 58       rule62 -0.2775102443 Ozone &gt; 45 &amp; Solar.R &lt;= 275
## 36       rule39 -0.0469380322 Ozone &gt; 14 &amp; Solar.R &lt;= 201
## 40       rule43 -0.0352134314  Temp &gt; 72 &amp; Solar.R &lt;= 255
## 51        rule5  0.0318214524                 Ozone &lt;= 52
## 10       rule10  0.0700563667                  Temp &lt;= 73
## 19       rule22  0.0669623307                 Ozone &lt;= 63
## 14       rule15  0.0010440732 Ozone &lt;= 45 &amp; Solar.R &gt; 212
## 55        Ozone -0.0003158451         7 &lt;= Ozone &lt;= 118.8</code></pre>
<p>We have obtained a final ensemble of 17 terms.</p>
</div>
<div id="multiple-imputation-a-sinlge-long-dataset" class="section level2">
<h2>Multiple imputation: A sinlge long dataset</h2>
<p>We aggregate the imputed datasets into one long dataset:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>imp2 <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp, <span class="st">&quot;long&quot;</span>, <span class="at">include =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>We fit the prediction rule ensemble to the long dataset:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>airq.imp <span class="ot">&lt;-</span> <span class="fu">pre</span>(Wind <span class="sc">~</span> ., <span class="at">data =</span> imp2[ , <span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)])</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(airq.imp)</span></code></pre></div>
<pre><code>## 
## Final ensemble with cv error within 1se of minimum: 
##   lambda =  0.007047102
##   number of terms = 95
##   mean cv error (se) = 3.496237 (0.2280665)
## 
##   cv error type : Mean-Squared Error</code></pre>
<p>We have obtained a very large ensemble, which is mostly due to the artificially inflated sample size. With lasso regression, we minimize the following criterion:</p>
<p><span class="math display">\[\frac{1}{2n} RSS + \lambda |\beta|\]</span></p>
<p>That is, for every unit increase in the L1 norm of the regression coefficients, we need to have a reduction of <span class="math inline">\(\lambda \times \frac{1}{2n}\)</span> in the RSS. We have artificially multiplied the sample size by 5, so the RSS will also multiply by 5; thus <span class="math inline">\(\frac{1}{2n} RSS\)</span> multiplies by <span class="math inline">\(\frac{5}{2n} RSS\)</span>.</p>
<p>Now, we correct the optimal <span class="math inline">\(\lambda\)</span> value for this artificial inflation of sample size: We take the optimal <span class="math inline">\(\lambda\)</span> from the dataset with sample size <span class="math inline">\(5n\)</span>, and we multiply it by <span class="math inline">\(\frac{2n}{5}\)</span>; this is the optimal <span class="math inline">\(\lambda\)</span> we should be using:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(airq.imp, <span class="at">penalty.par.val =</span> airq.imp<span class="sc">$</span>glmnet.fit<span class="sc">$</span>lambda<span class="fl">.1</span>se <span class="sc">*</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">nrow</span>(airquality)<span class="sc">/</span><span class="dv">5</span>)</span></code></pre></div>
<pre><code>## Final ensemble with lambda =  0.4224627
##   number of terms = 5
##   mean cv error (se) = 9.214077 (0.4598044)
## 
##   cv error type : Mean-Squared Error</code></pre>
<p>We have now obtained a much smaller ensemble.</p>
</div>
<div id="comparison" class="section level2">
<h2>Comparison</h2>
<p>We compare performance using 10-fold cross validation. As a benchmark, we take a listwise deletion approach. We only evaluate accuracy for observations that have no missing values.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>fold_ids <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>k, <span class="at">size =</span> <span class="fu">nrow</span>(airquality), <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>observed <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Separate training and test data</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  test <span class="ot">&lt;-</span> airquality[fold_ids <span class="sc">==</span> i, ]</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  test <span class="ot">&lt;-</span> test[<span class="sc">!</span><span class="fu">is.na</span>(test<span class="sc">$</span>Ozone), ]</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  test <span class="ot">&lt;-</span> test[<span class="sc">!</span><span class="fu">is.na</span>(test<span class="sc">$</span>Solar.R), ]</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  observed <span class="ot">&lt;-</span> <span class="fu">c</span>(observed, test<span class="sc">$</span>Wind)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(observed)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>preds<span class="sc">$</span>LW <span class="ot">&lt;-</span> preds<span class="sc">$</span>MI_agg <span class="ot">&lt;-</span> preds<span class="sc">$</span>MI_long <span class="ot">&lt;-</span> preds<span class="sc">$</span>observed</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>row <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (i <span class="sc">&gt;</span> <span class="dv">1</span>) row <span class="ot">&lt;-</span> row <span class="sc">+</span> <span class="fu">nrow</span>(test)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Separate training and test data</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>  train <span class="ot">&lt;-</span> airquality[fold_ids <span class="sc">!=</span> i, ]</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>  test <span class="ot">&lt;-</span> airquality[fold_ids <span class="sc">==</span> i, ]</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>  test <span class="ot">&lt;-</span> test[<span class="sc">!</span><span class="fu">is.na</span>(test<span class="sc">$</span>Ozone), ]</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>  test <span class="ot">&lt;-</span> test[<span class="sc">!</span><span class="fu">is.na</span>(test<span class="sc">$</span>Solar.R), ]</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Fit and evaluate listwise deletion</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>  premod <span class="ot">&lt;-</span> <span class="fu">pre</span>(Wind <span class="sc">~</span> ., <span class="at">data =</span> train)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>  preds<span class="sc">$</span>LW[row<span class="sc">:</span>(row<span class="sc">+</span><span class="fu">nrow</span>(test)<span class="sc">-</span><span class="dv">1</span>)] <span class="ot">&lt;-</span> <span class="fu">predict</span>(premod, <span class="at">newdata =</span> test)</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Perform multiple imputation</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>  imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(train, <span class="at">m =</span> <span class="dv">5</span>)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>  imp1 <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp, <span class="at">action =</span> <span class="st">&quot;all&quot;</span>, <span class="at">include =</span> <span class="cn">FALSE</span>)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>  imp2 <span class="ot">&lt;-</span> <span class="fu">complete</span>(imp, <span class="st">&quot;long&quot;</span>, <span class="at">include =</span> <span class="cn">FALSE</span>)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Fit and evaluate aggregated ensembles approach</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>  airq.agg <span class="ot">&lt;-</span> <span class="fu">pre.agg</span>(imp1, <span class="at">formula =</span> Wind <span class="sc">~</span> .)</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>  preds<span class="sc">$</span>MI_agg[row<span class="sc">:</span>(row<span class="sc">+</span><span class="fu">nrow</span>(test)<span class="sc">-</span><span class="dv">1</span>)] <span class="ot">&lt;-</span> <span class="fu">predict.agg</span>(airq.agg, <span class="at">newdata =</span> test)</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Fit and evaluate the single long dataset approach</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>  airq.imp <span class="ot">&lt;-</span> <span class="fu">pre</span>(Wind <span class="sc">~</span> ., <span class="at">data =</span> imp2[ , <span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)])</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>  preds<span class="sc">$</span>MI_long[row<span class="sc">:</span>(row<span class="sc">+</span><span class="fu">nrow</span>(test)<span class="sc">-</span><span class="dv">1</span>)] <span class="ot">&lt;-</span> <span class="fu">predict</span>(airq.imp, </span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">penalty.par.val =</span> airq.imp<span class="sc">$</span>glmnet.fit<span class="sc">$</span>lambda<span class="fl">.1</span>se <span class="sc">*</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">nrow</span>(train)<span class="sc">/</span><span class="dv">5</span>,</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> test)</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(preds, <span class="cf">function</span>(x) <span class="fu">mean</span>((preds<span class="sc">$</span>observed <span class="sc">-</span> x)<span class="sc">^</span><span class="dv">2</span>)) <span class="do">## MSE</span></span></code></pre></div>
<pre><code>## observed  MI_long   MI_agg       LW 
## 0.000000 9.297116 9.561734 9.841378</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(preds, <span class="cf">function</span>(x) <span class="fu">sd</span>((preds<span class="sc">$</span>observed <span class="sc">-</span> x)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">nrow</span>(preds))) <span class="do">## SE of MSE</span></span></code></pre></div>
<pre><code>## observed  MI_long   MI_agg       LW 
## 0.000000 1.469149 1.482694 1.525691</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(preds<span class="sc">$</span>observed) <span class="do">## benchmark: Predict mean for all</span></span></code></pre></div>
<pre><code>## [1] 12.65732</code></pre>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(preds)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>we see that all three methods yields very similar predictions and accuracy. The ‘single long dataset’ multiple imputation method performed best, followed by the ‘aggragated ensembles’ imputation method, followed by listwise deletion. The standard errors indicate that in terms of variance, the methods have the same ordering. The differences in performance are small, though. In light of the sparsity and accuracy of the single-long-dataset multiple imputation method, perhaps this one should be preferred.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Josse, J., Prost, N., Scornet, E., &amp; Varoquaux, G. (2019). On the consistency of supervised learning with missing values. <em>arXiv preprint arXiv:1902.06931</em>. <a href="https://arxiv.org/abs/1902.06931" class="uri">https://arxiv.org/abs/1902.06931</a></p>
<p>Miles, A. (2016). Obtaining predictions from models fit to multiply imputed data. <em>Sociological Methods &amp; Research, 45</em>(1), 175-185. <a href="https://doi.org/10.1177/0049124115610345" class="uri">https://doi.org/10.1177/0049124115610345</a></p>
<p>Schafer, J. L., &amp; Graham, J. W. (2002). Missing data: our view of the state of the art. <em>Psychological Methods, 7</em>(2), 147. <a href="https://doi.org/10.1037/1082-989X.7.2.147" class="uri">https://doi.org/10.1037/1082-989X.7.2.147</a></p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
